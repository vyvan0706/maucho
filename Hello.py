import streamlit as st
import gtts
from ftlangdetect import detect as lang_detector
from deep_translator import GoogleTranslator
st.title(':rainbow[L·ªìng ti·∫øng v·ªõi ch·ªã Google]')
st.image('https://nguyendang.net.vn/wp-content/uploads/2021/06/google-translate-extension-TIEN-ICH-MO-RONG-GOOGLE-DICH.jpg',width=100)
user_input= st.text_area('Nh·∫≠p vƒÉn b·∫£n mu·ªën l·ªìng ti·∫øng')
language_code_mapping={
     'Ti·∫øng Vi·ªát':'vi',
     'Ti·∫øng Anh':'en',
     'Ti·∫øng H√†n':'ko',
     'Ti·∫øng Nh·∫≠t':'ja'
} 
translate = st.toggle(':red[D·ªãch vƒÉn b·∫£n]')
if translate:
     target_language= st.selectbox(
    'Ch·ªçn ng√¥n ng·ªØ c·ªßa b·∫£n d·ªãch',
    ('Ti·∫øng Vi·ªát','Ti·∫øng Anh','Ti·∫øng H√†n','Ti·∫øng Nh·∫≠t'))
     target_language_code=language_code_mapping[target_language]
submitbut=st.button('X√°c nh·∫≠n')
if user_input and submitbut:
     language_code=lang_detector(user_input)['lang']
     result= gtts.gTTS(text=user_input, lang=language_code)
     result.save('S2/result.mp3')
     col1,col2=st.columns(2)
     with col1:
       st.toast('c·∫£m ∆°n b·∫°n',icon='üéà')
       st.subheader('VƒÉn b·∫£n g·ªëc')
       st.audio('S2/result.mp3')
     if translate:
          st.balloons()
          translated_input = GoogleTranslator(source='auto', target=target_language_code).translate(user_input)  
          trans_result= gtts.gTTS(text=translated_input, lang=target_language_code)
          trans_result.save('S2/trans_result.mp3')
          with col2:
            st.subheader('VƒÉn b·∫£n d·ªãch')
            st.audio('S2/trans_result.mp3')